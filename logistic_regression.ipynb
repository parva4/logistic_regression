{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "IMnkeiW3xjXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_blobs(n_samples=5000,\n",
        "                  n_features=2,\n",
        "                  shuffle=True,\n",
        "                  centers=2,\n",
        "                  random_state=42)"
      ],
      "metadata": {
        "id": "-kd_aP7axgxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMgDc_haxcyQ"
      },
      "outputs": [],
      "source": [
        "class Logistic_Regression:\n",
        "\n",
        "  def __init__(self,X,y,learning_rate,tolerance,max_iter):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.learning_rate=learning_rate\n",
        "    self.tolerance=tolerance\n",
        "    self.max_iter=max_iter\n",
        "\n",
        "  def split_train_test(self,X,y):\n",
        "    X_train,X_test,y_train,y_test = train_test_split(X,\n",
        "                                                     y,\n",
        "                                                     train_size=0.75,\n",
        "                                                     random_state=0,\n",
        "                                                     shuffle=True)\n",
        "    return X_train,X_test,y_train,y_test\n",
        "\n",
        "  def sigmoid(self,z):\n",
        "    sigmoid = 1 / (1+np.exp(-z))\n",
        "    return sigmoid\n",
        "\n",
        "  def predict(self,X):\n",
        "    return X.dot(self.w)\n",
        "\n",
        "  def cost_function(self,X,y):\n",
        "    sig = self.sigmoid(self.predict(X))\n",
        "    loss = y.dot(np.log(sig)) + (1-y).dot(np.log(1-sig))\n",
        "    cost = -loss.sum()\n",
        "    return cost\n",
        "\n",
        "  def costDerivative(self,X,y):\n",
        "    sig = self.sigmoid(self.predict(X))\n",
        "    gradient = (sig - y).dot(X)\n",
        "    return gradient\n",
        "\n",
        "  def gradientDescent(self,X,y):\n",
        "    self.w = np.ones(X.shape[1])\n",
        "    last = float('inf')\n",
        "    errors = []\n",
        "\n",
        "    for i in tqdm(range(self.max_iter)):\n",
        "      self.w = self.w - self.learning_rate * self.costDerivative(X,y)\n",
        "      error = self.cost_function(X,y)\n",
        "      errors.append(error)\n",
        "      diff = abs(error - last)\n",
        "      last = error\n",
        "\n",
        "      if diff < self.tolerance:\n",
        "        print('model converged after iteration {}'.format(i))\n",
        "        break\n",
        "\n",
        "    print('coefficients are : {}'.format(self.w))\n",
        "\n",
        "  def execute(self):\n",
        "    X_train,X_test,y_train,y_test = self.split_train_test(self.X,self.y)\n",
        "    self.gradientDescent(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log = Logistic_Regression(X=X,\n",
        "                          y=y,\n",
        "                          learning_rate=0.000005,\n",
        "                          max_iter=10000,\n",
        "                          tolerance=0)"
      ],
      "metadata": {
        "id": "vm9Ckb-wxnV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log.execute()"
      ],
      "metadata": {
        "id": "7E8hzci5xn0V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}